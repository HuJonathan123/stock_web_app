import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import load_model
import os
import json
import glob
import datetime

# ===========================
# ğŸ”® å¯¦æˆ°é æ¸¬è…³æœ¬ (JSON ä¿®å¾©ç‰ˆ)
# ===========================
MODEL_BASE_DIR = "saved_models"
DATA_DIR = "data"

def find_latest_model_dir():
    # å„ªå…ˆæ‰¾ latest è³‡æ–™å¤¾
    latest = os.path.join(MODEL_BASE_DIR, "latest")
    if os.path.exists(latest): return latest
    
    # å¦å‰‡æ‰¾æœ€æ–°çš„
    dirs = glob.glob(os.path.join(MODEL_BASE_DIR, "*"))
    if not dirs: return None
    return max(dirs, key=os.path.getmtime)

def prepare_data(df, look_back):
    if len(df) < look_back: return None, None
    data = df.filter(['Close']).values
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)
    last_sequence = scaled_data[-look_back:].reshape(1, look_back, 1)
    return last_sequence, scaler

def run_prediction():
    print("ğŸ¤– AI æ­£åœ¨åˆ†æå³æ™‚å¸‚å ´æ•¸æ“š...")
    model_dir = find_latest_model_dir()
    if not model_dir:
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹ï¼Œè«‹å…ˆåŸ·è¡Œå›æ¸¬ï¼")
        return
        
    config_path = os.path.join(model_dir, "config.json")
    if not os.path.exists(config_path):
        print("âŒ æ‰¾ä¸åˆ° config.json")
        return

    with open(config_path, "r") as f:
        config = json.load(f)
        
    tickers = config.get('TICKERS', [])
    look_back = config.get('LOOK_BACK', 60)
    predict_days = config.get('PREDICT_DAYS', 10)
    
    results = []
    
    for t in tickers:
        try:
            model_path = os.path.join(model_dir, f"{t}.keras")
            if not os.path.exists(model_path): continue
            
            model = load_model(model_path)
            # æŠ“å–æœ€è¿‘ 1.5 å¹´æ•¸æ“šä»¥ç¢ºä¿æœ‰è¶³å¤ çš„ Lookback
            df = yf.download(t, period="2y", progress=False)
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
            
            if len(df) < look_back: continue

            input_seq, scaler = prepare_data(df, look_back)
            if input_seq is None: continue
            
            preds = []
            curr_input = input_seq
            for _ in range(predict_days):
                pred = model.predict(curr_input, verbose=0)
                preds.append(pred[0, 0])
                curr_input = np.append(curr_input[:, 1:, :], [[pred[0]]], axis=1)
                
            real_preds = scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()
            
            # ğŸ”¥ å¼·åˆ¶è½‰å‹ç‚º Python åŸç”Ÿ float (è§£æ±º JSON error)
            current_price = float(df['Close'].iloc[-1])
            max_future = float(np.max(real_preds))
            roi = float((max_future - current_price) / current_price * 100)
            
            # æ­·å²æ•¸æ“š (ä¾›ç•«åœ–) - åŒæ¨£å¼·åˆ¶è½‰å‹
            hist = [float(x) for x in df['Close'].iloc[-60:].values]
            forecast = [float(x) for x in real_preds]
            
            results.append({
                "Ticker": t,
                "Current_Price": current_price,
                "Predicted_High": max_future,
                "ROI": roi,
                "Forecast_Curve": forecast,
                "History_Curve": hist
            })
            print(f"âœ… {t}: {roi:+.2f}%")
            
        except Exception as e:
            print(f"âŒ {t} å¤±æ•—: {e}")
            
    results.sort(key=lambda x: x['ROI'], reverse=True)
    
    output = {
        "analysis_date": datetime.datetime.now().strftime("%Y-%m-%d"),
        "top_pick": results[0] if results else None,
        "all_rankings": results
    }
    
    with open(os.path.join(DATA_DIR, "ai_lab_result.json"), "w") as f:
        json.dump(output, f)
    
    print("ğŸ‰ é æ¸¬å®Œæˆï¼çµæœå·²æ›´æ–°ã€‚")

if __name__ == "__main__":
    run_prediction()