import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import os
import json
import datetime

# ===========================
# è¨­å®šèˆ‡åƒæ•¸
# ===========================
DATA_DIR = "data"
if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)

# ç‚ºäº†ç¯€çœæ¸¬è©¦æ™‚é–“ï¼Œæˆ‘å€‘å…ˆåªè·‘é€™ 5 æ”¯é‡é»è‚¡ç¥¨
# ç­‰ç¢ºèªæ²’å•é¡Œäº†ï¼Œå†æŠŠæ•´ä¸²åå–®æ”¾é€²å»
TICKERS = ['NVDA', 'TSLA', 'AMZN', 'MSFT', 'GOOGL'] 

LOOK_BACK = 60  # å›çœ‹éå» 60 å¤©
FORECAST_DAYS = 10 # é æ¸¬æœªä¾† 10 å¤©

# ===========================
# 1. æ•¸æ“šæº–å‚™ (æ­£è¦åŒ–)
# ===========================
def prepare_data(df, look_back):
    data = df.filter(['Close']).values
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)
    
    x_train, y_train = [], []
    # å»ºç«‹æ»‘å‹•è¦–çª—æ•¸æ“š
    for i in range(look_back, len(scaled_data)):
        x_train.append(scaled_data[i-look_back:i, 0])
        y_train.append(scaled_data[i, 0])
        
    x_train, y_train = np.array(x_train), np.array(y_train)
    # LSTM éœ€è¦ä¸‰ç¶­è¼¸å…¥ [Samples, Time Steps, Features]
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
    
    return x_train, y_train, scaler, scaled_data

# ===========================
# 2. å»ºç«‹ LSTM æ¨¡å‹æ¶æ§‹
# ===========================
def build_model(input_shape):
    model = Sequential()
    # ç¬¬ä¸€å±¤ LSTM
    model.add(LSTM(50, return_sequences=False, input_shape=input_shape))
    # å…¨é€£æ¥å±¤
    model.add(Dense(25))
    # è¼¸å‡ºå±¤
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# ===========================
# 3. åŸ·è¡Œåˆ†æä¸»ç¨‹åº
# ===========================
def run_ai_analysis():
    print(f"ğŸ§  AI å¯¦é©—å®¤å•Ÿå‹•... æº–å‚™åˆ†æ {len(TICKERS)} æª”è‚¡ç¥¨")
    results = []
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    
    # æŠ“å–éå» 2 å¹´æ•¸æ“š (æ•¸æ“šå¤šä¸€é»è¨“ç·´æ¯”è¼ƒæº–)
    start_date = (datetime.datetime.now() - datetime.timedelta(days=730)).strftime("%Y-%m-%d")
    
    for ticker in TICKERS:
        try:
            print(f"ğŸ‘‰ æ­£åœ¨è¨“ç·´æ¨¡å‹: {ticker} ...")
            df = yf.download(ticker, start=start_date, progress=False)
            
            # è™•ç† MultiIndex (yfinance æ–°ç‰ˆå•é¡Œ)
            if isinstance(df.columns, pd.MultiIndex): 
                df.columns = df.columns.get_level_values(0)
            
            if len(df) < 100: 
                print(f"âš ï¸ {ticker} æ•¸æ“šä¸è¶³ï¼Œè·³é")
                continue

            # æº–å‚™æ•¸æ“š
            x_train, y_train, scaler, scaled_data = prepare_data(df, LOOK_BACK)
            
            # å»ºç«‹ä¸¦è¨“ç·´æ¨¡å‹
            # epochs=5 (è¨“ç·´ 5 è¼ªï¼Œæœ¬æ©Ÿæ¸¬è©¦æ¯”è¼ƒå¿«)
            model = build_model((x_train.shape[1], 1))
            model.fit(x_train, y_train, batch_size=16, epochs=5, verbose=0)
            
            # --- é–‹å§‹é æ¸¬æœªä¾† ---
            # æ‹¿å‡ºæœ€å¾Œ 60 å¤©çš„æ•¸æ“šä½œç‚ºèµ·é»
            last_sequence = scaled_data[-LOOK_BACK:]
            curr_input = last_sequence.reshape(1, LOOK_BACK, 1)
            
            predicted_prices_scaled = []
            
            # è¿­ä»£é æ¸¬æœªä¾† N å¤©
            for _ in range(FORECAST_DAYS):
                # é æ¸¬ä¸‹ä¸€å¤©
                next_pred = model.predict(curr_input, verbose=0)
                predicted_prices_scaled.append(next_pred[0, 0])
                
                # æ›´æ–°è¼¸å…¥æ•¸æ“šï¼šç§»é™¤ç¬¬ä¸€å¤©ï¼ŒåŠ å…¥å‰›å‰›é æ¸¬å‡ºä¾†çš„ä¸€å¤©
                # é€™æ¨£æ‰èƒ½åƒæ¥é¾ä¸€æ¨£å¾€å¾Œé æ¸¬
                curr_input = np.append(curr_input[:, 1:, :], [[next_pred[0]]], axis=1)
            
            # å°‡é æ¸¬çµæœè½‰å›çœŸå¯¦åƒ¹æ ¼
            predicted_prices = scaler.inverse_transform(np.array(predicted_prices_scaled).reshape(-1, 1))
            predicted_prices = predicted_prices.flatten().tolist()
            
            # è¨ˆç®—æŒ‡æ¨™
            current_price = float(df['Close'].iloc[-1])
            max_future_price = max(predicted_prices)
            potential_roi = (max_future_price - current_price) / current_price * 100
            
            print(f"   âœ… {ticker} å®Œæˆ | ç¾åƒ¹: {current_price:.1f} -> é æ¸¬é«˜é»: {max_future_price:.1f} ({potential_roi:+.2f}%)")
            
            results.append({
                "Ticker": ticker,
                "Current_Price": current_price,
                "Predicted_Max": max_future_price,
                "Potential_ROI": potential_roi,
                "Forecast_Curve": predicted_prices
            })
            
        except Exception as e:
            print(f"âŒ {ticker} å¤±æ•—: {e}")

    # æ’åºï¼šæ½›åŠ›æœ€é«˜çš„æ’å‰é¢
    results.sort(key=lambda x: x['Potential_ROI'], reverse=True)
    
    # å­˜æª”
    output = {
        "analysis_date": today,
        "top_pick": results[0] if results else None,
        "all_rankings": results
    }
    
    with open(os.path.join(DATA_DIR, "ai_lab_result.json"), "w") as f:
        json.dump(output, f)
    
    print("\nğŸ‰ åˆ†æå…¨éƒ¨å®Œæˆï¼çµæœå·²å„²å­˜è‡³ data/ai_lab_result.json")

if __name__ == "__main__":
    run_ai_analysis()